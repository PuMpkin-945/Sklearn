# 无监督学习
    没有给定事先标记过的训练示例，自动对输入的数据进行分类或分群。

## 聚类分析
    根据对象某些属性的相似度，将其自动化分为不同的类别。
     
    1. KMeans聚类 
        * 根据数据与中心点距离划分类别
        * 基于类别数据更新中心点
        * 重复过程直到收敛
    实现简单，收敛快；需要指定类别数量
    
    2. 均值漂移聚类（Meanshift）
        * 在中心点一定区域检索数据点
        * 更新中心
        * 重复流程到中心点稳定
    自动发现类别数量，不需要人工选择；需要选择区域半径

    3. DBSCAN算法（基于密度的空间聚类算法）
        *基于区域点密度筛选有效数据
        *基于有效数据向周边扩张，指导没有新点加入
    过滤噪音数据；不需要人为选择类别数量；数据密度不同时影响结果

## Kmeans（K均值聚类）
    K-均值算法：以空间中k个点为中心进行聚类，对最靠近他们的对象归类，是聚类算法中最为基础但也最为重要的算法。
**公式：**
    数据点与各簇中心点距离：$dist(x_i, u_j^t)$
    根据距离归类：$x_i \in u_nearst^t$
    中心点更新：$u_j^{t+1} = \frac{1}{k} \sum_{x_i \in S_j} x_i$
$S_j$:t时刻第j个区域簇；k:包含在$S_j$范围内点的个数；$x_i$:包含在$S_j$范围内的点；$u_j^t$为t状态下第j区域中心
    **算法流程：**
    1. 选择聚类的个数k
    2. 确定聚类中心
    3. 根据点到聚类中心聚类确定各个点所属类别
    4. 根据各个类别数据更新聚类中心
    5. 重复以上步骤直到收敛（中心点不再变化）
    **优点**
    1. 原理简单，实现容易，收敛速度快
    2. 参数少，方便使用
    **缺点**
    1. 必须设置簇的数量
    2.随机选择初始聚类中心，结果可能缺乏一致性

**和K近邻分类（KNN）作比较**
![K-means VS Knn](https://raw.githubusercontent.com/PuMpkin-945/my_image/main/Kmeans_KNN.png)
    给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

## 均值漂移聚类
    一种基于密度梯度上升的聚类算法（沿着密度上升方向寻找聚类中心点）
**公式：**
![Meanshift](https://raw.githubusercontent.com/PuMpkin-945/my_image/main/Meanshift.png)
    均值漂移：$M(x) = \frac{1}{k} \sum_{x_i \in S_h}(u - x_i)$
    中心更新：$u^{t+1} = M^t + u^t$
$S_h$:以u为中心点，半径为h的高维球区域；k:包含在$S_h$范围内点的个数；$x_i$:包含在$S_h$范围内的点；
$M^t$为t状态下求得的偏移均值；$u^t$为t状态下的中心
     **算法流程**
    1. 随机选择未分类点作为中心点
    2. 找出离中心点到集合S中每个元素的偏移向量M
    3. 计算从中心点到集合S中每个元素的偏移向量M
    4. 中心点以向量M移动
    5. 重复步骤2-4，直到收敛
    6. 重复1-5直到所有的点都被归类
    7. 分类：根据每个类，对每个点的访问频率，取访问频率最大的那个类，作为当前点集的所属类

KMeans、KNN、Mean-shift算法各自的特点，划分数据任务中如何执行？















    